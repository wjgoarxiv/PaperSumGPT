ChatGPT: A Meta-Analysis after 2.5 Months
Christoph Leiter and Ran Zhang and Yanran Chen
and Jonas Belouadi and Daniil Larionov and Vivian Fresen and Steffen Eger
{ran.zhang,christoph.leiter,daniil.larionov,jonas.belouadi,steffen.eger}
  @uni-bielefeld.de, ychen@techfak.uni-bielefeld.de, V.Fresen@crif.com
Natural Language Learning Group (NLLG) Faculty of Technology, Bielefeld University nl2g.github.io

Abstract
ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media atten- tion since its release in November 2022. How- ever, little hard evidence is available regarding its perception in various sources. In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how Chat- GPT is perceived and discussed. Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emo- tions of joy dominating in social media. Its perception has slightly decreased since its de- but, however, with joy decreasing and (nega- tive) surprise on the rise, and it is perceived more negatively in languages other than En- glish. In recent scientific papers, ChatGPT is characterized as a great opportunity across var- ious fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education. Our compre- hensive meta-analysis of ChatGPT’s current perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development. We make our data available.1
1 Introduction
ChatGPT2 — a chatbot released by OpenAI in November 2022 which can answer questions, write fiction or prose, help debug code, etc. — has seem- ingly taken the world by storm. Over the course of just a little more than two months, it has at- tracted more than 100 million subscribers, and has been described as the fastest growing web platform ever, leaving behind Instagram, Facebook, Netflix and TikTok3 (Haque et al., 2022). Its qualities have been featured, discussed and praised by popular media,4 laymen5 and experts alike. On social media, it has (initially) been lauded as “Artificial General Intelligence”,6 while more recent assessment hints at limitations and weaknesses e.g. regarding its reasoning and mathematical abilities (Borji, 2023; Frieder et al., 2023) (the authors of this work point out that, as of mid-February 2023, even after 5 up- dates, ChatGPT can still not accurately count the number of words in a sentence — see Figure 13 — a task primary school children would typically solve with ease.).
However, while there is plenty of anecdotal evi- dence regarding the perception of ChatGPT, there is little hard evidence via analysis of different sources such as social media and scientific papers published on it. In this paper, we aim to fill this gap. We ask how ChatGPT is viewed from the perspectives of different actors, how its perception has changed over time and which limitations and strengths have been pointed out. We focus specifically on Social Media (Twitter), collecting over 300k tweets, as well as scientific papers from Arxiv and Semantic- Scholar, analyzing more than 150 papers.
We find that ChatGPT is overall characterized in different sources as of high quality, with positive sentiment and associated emotions of joy dominat- ing. In scientific papers, it is characterized pre- dominantly as a (great) opportunity across various fields, including the medical area and various ap- plications including (scientific) writing as well as for businesses, but also as a threat from an ethical perspective. The assessed impact in the education domain is more mixed, where ChatGPT is viewed both as an opportunity for shifting focus to teach- ing advanced writing skills (Bishop, 2023) and for making writing more efficient (Zhai, 2022) but also a threat to academic integrity and fostering dishon-esty (Ventayen, 2023). Its perception has, however, slightly decreased in social media since its debut, with joy decreasing and surprise on the rise. In addition, in languages other than English, it is per- ceived with more negative sentiment.
By providing a comprehensive assessment of its current perception, our paper can contribute to shaping the public debate and informing the future development of ChatGPT.
2 Analyses
2.1 Social Media Analysis
We aim to acquire insights into public opinion and sentiment on ChatGPT and understand public atti- tudes toward different topics related to ChatGPT. We choose Twitter as our social media source and collect tweets since the publication date of Chat- GPT. The following will introduce the data and the preprocessing steps.
Dataset We obtain data through the use of a hash- tag search tool snscrape,7 setting our search target as #ChatGPT. After acquiring the data, we dedupli- cate all the retweets and remove robots.8
Our final dataset contains tweets in the time period from 2022-11-30 18:10:57 to 2023-02-09 17:24:45. The information is summarized in Table 1. We collect over 330k tweets from more than 168k unique user accounts. The average “age” over all user accounts is 2,807 days. On average, each user generates 1.99 tweets over the time period. The dataset contains tweets across 61 languages. Over 68% of them are in English, other major languages are Japanese (6.4%), Spanish (5.3%), French (5.0%), and German (3.3%). We translate all tweets into English via a multi-lingual machine
translation model developed by Facebook.9
Sentiment Analysis We utilize the multi-lingual sentiment classifier from Barbieri et al. (2022) to ac- quire the sentiment label. This XLM-Roberta based language model is trained on 198 million tweets, and finetuned on Twitter sentiment dataset in eight different languages. The model performance on sentiment analysis varies among languages (e.g. the F1-score for Hindi is only 53%), but the model yields acceptable results in English with an F1- score of 71%. Thus we choose English as our sole input language and collect negative, neutral, and positive sentiments over time (represented as classes 0,1,2, respectively). Table 2 summarizes the sentiment distribution of all tweets. While the majority of the sentiment is neutral, there is a rela- tively large proportion of positive sentiment, with 100k instances, and a smaller but still notable num- ber of tweets of negative sentiments, with 60k in- stances. Table 3 provides sample tweets belonging to different sentiment groups.
To examine the sentiment change over time, we plot the weekly average of sentiment and the weekly percentage of positive, neutral, and nega- tive tweets in Figure 1. From the upper plot, we observe an overall downward trend of sentiment (black solid line) during the course of ChatGPT’s first 2.5 months: an initial rise in average sentiment was followed by a decrease from January 2023 onwards. We note, however, that the decline is mild in absolute value: the average sentiment of a tweet decreases from a maximum of about 1.15 to a minimum of 1.10 (which also indicates that the average sentiment of tweets is slightly more positive than neutral). We also report the average sentiment of English tweets (dotted line) and non- English tweets(dashed line). Though the absolute difference is small, we can clearly identify the divi- sion of sentiment between English and non-English tweets. The difference in sentiment is narrowing over time, but overall tweets in English have a more positive perception of ChatGPT. This suggests that ChatGPT may be better in English, which consti- tuted the majority of its training data; but see also our topic-based analysis below.
The bar plots in the lower part of the figure rep- resent the count of tweets per week and the line plots show the percentage change of each sentiment class. While the percentage of negative tweets is stable over time, the percentage of positive tweets decreases and there is a clear increase in tweets with the neutral sentiment. This may indicate that the public view of ChatGPT is becoming more ra- tional after an initial hype of this new “seemingly omnipotent” bot.
During the course of 2.5 months after ChatGPT’s debut, OpenAI announced 5 new releases claiming various updates. Our data covers the period of the first three releases on the 15th of December 2022, the 9th of January, and the 3rd of January in 2023. The two latest releases on the 9th of February and the 13th of February are not included in this study.10 The three update time points of ChatGPT are depicted as vertical dashed lines in the lower plot of Figure 1. We can observe small short-term increases in sentiment after each new release.
Sentiment across language and topic. We no- tice from Figure 1 that the sentiments among En- glish and non-English tweets vary. Here we analyze
sentiment based on all 5 major languages in our ChatGPT dataset, namely English (en), Japanese (ja), Spanish (es), French (fr), and German (de). Figure 2 demonstrates the weekly average senti- ment of each language over time. As indicated by our previous observation in Figure 1, tweets in En- glish have the most positive view of ChatGPT. It is also worth noting that over the time period, the sentiment of English, German, and French tweets are trending downward while Spanish and Japanese tweets start from a low point and trend upwards.
To answer why this is the case, we introduce topic labels into our analysis. To do so, we uti- lize the monolingual (English) topic classification model developed by Antypas et al. (2022). This Roberta-based model is trained on 124 million tweets and finetuned for multi-label topic classi- fication on a corpus of over 11k tweets. The model has 19 classes of topics. We only focus on 5 major classes, which cover 86.3% of tweets in our dataset: science & technology (38.6%), learning & educa- tional (15.2%), news & social concern (13.0%), diaries & daily life (10.2%), and business & en- trepreneurs (9.3%). The upper plot of Figure 3 depicts the topic distribution in percentage by dif- ferent languages. The share of science & technol- ogy topic ranks the highest in all of the 5 languages. However, German and French tweets have a rela- tively higher share of learning & educational and news & social concern topics compared to English and Spanish. We report the sentiment distribution over different topics in Figure 4. From this plot, we notice that the topic business & entrepreneurs has the lowest proportion of negative tweets while the topic news & social concern contains the highest proportion of negative tweets. For the other three topics, even though their share of positive tweets are similar, diaries & daily life topic contains more negative tweets proportionally.
This observation may explain the differences in sentiment distribution among different languages. Compared to other languages, English tweets have the highest proportion of business & entrepreneurs and science & technology, both of which contain the lowest share of negative views about ChatGPT. French and German tweets have a similar propor- tion of news & social concern topics, which may result in their slightly less positivity than English tweets, though the three of them have similar over- all trends. The case for Japanese and Spanish is unique in terms of the low initial sentiment. The lower plot in Figure 3, which shows the topic distri- bution change over time for Japanese tweets, may explain this phenomenon. We can observe an evi- dent increase in topics concerning business & en- trepreneurs and science & technology, which con- tribute more positivity, and a decrease in news & social concern, which reduces the share of nega- tive tweets. The same explanation may apply to Spanish tweets.
Aspect of the sentiment To further obtain an un- derstanding of aspects of sentiments in negative and positive tweets, we manually annotated and analyzed the sentiment expressed within 40 ran- domly selected tweets. We draw 20 random posi- tive tweets from the period including the last two weeks of 2022 and the first week of 2023, where he general sentiment reaches the peak, and 20 ran- dom negative tweets from the second week to the fourth week of 2023, where the general sentiment declines. We are particularly interested in what users find positive/negative about ChatGPT, which in general could relate to many things, e.g., its qual- ity, downtimes, etc.
Based on our analysis of a sample of 20 tweets during the first period, we observed a prevalent positive sentiment towards ChatGPT’s ability to generate human-like and concise text. Specifically, 14 out of 20 users reported evident admiration for the model and the text it produced. Users particu- larly noted the model’s capacity to answer complex medical questions, generate rap lyrics and tailor texts to specific contexts. Notably, we also discov- ered instances where users published tweets that ChatGPT completely generated.
As for the randomly selected negative tweets of the second period, 13 out of the 20 users expressed frustration with the model. These users voiced con- cerns about potential factual inaccuracies in the generated text and the detectability of the model- generated text. Additionally, a few users expressed ethical concerns, with some expressing worries about biased output or the potential increase in misinformation. Our analysis also revealed that a minority of users expressed concerns over job loss to models like ChatGPT. Overall, these findings suggest that negative sentiment towards ChatGPT was primarily driven by concerns about the model’s limitations and its potential impact on society, par- ticularly in generating inaccurate or misleading information.
As part of our analysis, we manually evaluated the sentiment categories for the samples analyzed. We found that 25% (5 out of 20) of the automat- ically classified sentiment labels were incorrect during the first period. In the second period, we found that 20% (4 out of 20) of the assigned labels were incorrect. The majority of the misclassified tweets were determined to have a neutral sentiment. Despite these misclassifications, we consider the overall error rate of 22.5% (9 out of 40) acceptable for our use case. Especially, errors may cancel out in our aggregated analysis and it is worth pointing out that the main confusions were with the neutral class, not the confusion of negative and positive labels.
Emotion Analysis In addition to sentiment, we do a more fine-grained analysis based on the emo-
tions of the tweets. We use the emotion classifier (a BERT base model) finetuned on the GoEmo- tions dataset (Demszky et al., 2020) that contains texts from Reddit and their emotion labels based on Ekman’s taxonomy (Ekman, 1992) to categorize the translated English tweets into 7 dimensions: joy, surprise, anger, sadness, fear, disgust and neu- tral.11 Among all 334,808 tweets, the great major- ity are labeled as neutral (∼70%), followed by the ones classified as joy (17.6%) and surprise (9.8%); the tweets classified as the remaining 4 emotions compose only 2.7% of the whole dataset.
We demonstrate the weekly changes in the emo- tion distribution of joy and surprise tweets in Fig- ure 5. Here we only show the percentage distri- bution denoting the ratio of the tweets classified as a specific emotion to all tweets with emotions (i.e., the tweets which are not labeled as neutral). We observe that the percentage of joy tweets gen- erally decreases after the release, though it rises to some degree after each update, indicating that the users have less fun with ChatGPT over time. On the other hand, the percentage of surprise tweets is overall in an uptrend with slight declines between the update time points.
To gain more insights, we manually analyze five randomly selected tweets per emotion category for the release and each of the three update dates.12 Here, we focus on the joy and surprise tweets, as they dominate in the tweets with emotions; addi- tionally, we also include an analysis of fear tweets, because of the observed peak in their distribution trend at the first two update time points, which we believe could provide more insight into the users’ concerns across different updates. We collect a to- tal of 60 tweets for manual analysis (5 tweets × 4 dates × 3 emotions); we show one sample for each emotion in Table 4.
joy Our own annotation suggests that 2 out of 20 tweets were misclassified to this category. Among the 18 tweets correctly classified, 12 tweets directly expressed admiration or reported positive interac- tions with ChatGPT such as successfully perform- ing generation tasks or acquiring answers, 1 tweet conveyed a positive outlook of AI in NFT (Non- Fungible Token) and game production, and 5 tweets expressed joy which is, however, not (directly) related to ChatGPT. Interestingly, even though 3 tweets did not pertain directly to ChatGPT, they expressed delight in a talk, post, or interview about ChatGPT, and all of them were posted after the second or third updates.
fear 1 out of 20 tweets was found to be mis- classified, and 1 tweet expressed fear but was unrelated to ChatGPT. Among the remaining 18 tweets, 9 expressed scariness of ChatGPT be- cause of its strong capability, 1 user argued that google should be scared of ChatGPT, and the rest 8 tweets reported various concerns including pro- viding wrong/malicious information, job loss and the unethical use of ChatGPT. It is noteworthy that 7 out of the 8 tweets demonstrating concerns were published after the second or third updates.
surprise Among the sampled tweets, we found that more misclassified tweets may exist compared to the other two categories; the model tends to clas- sify the sentences with question marks as surprise. It is also a challenging task for humans to iden- tify “surprise” in a short sentence, as this emotion may involve different cognitive and perceptual pro- cesses. Moreover, “surprise” could have both nega- tive and positive connotation. Hence, we do a four- way manual sentiment annotation for the surprise tweets: positive, negative, mixed and unrelated. 12 out of 20 tweets were found to be correctly classi- fied as surprise, among which 6 tweets conveyed positive surprise due to ChatGPT’s impressive per- formance, 2 tweets expressed negative surprise in terms of providing inaccurate information and prej- udice against AI, and 4 tweets expressed positive surprise about ChatGPT but with negative concerns regarding unethical uses. We further consider all tweets expressing surprise before and after the 2nd update. Before the 2nd update, there were 1.13 times more positive sentiment surprise tweets than negative ones (4942 vs. 4372); after the second update, the ratio is roughly equal (5065 vs. 5093).
The decrease in joy tweets and the increase in negative surprise tweets over time — even though on relatively small levels — indicates a more nu- anced and rational assessment of ChatGPT over time, similar to the overall decline of positive senti- ment over time found in our initial sentiment anal- ysis. We still notice that, apart from neutral, joy is the most frequently expressed emotion for tweets relating to #ChatGPT in our sample.
2.2 Arxiv & SemanticScholar
Given the limited time frame of ChatGPT’s avail- ability, a substantial portion of potentially relevant papers on it are not yet available in officially pub- lished form. Thus, we focus our analysis on two sources of information: (1) preprints from Arxiv, which may or may not have already been published; and (2) non-Arxiv papers identified through Seman- ticScholar. The Arxiv preprints primarily comprise computer science and similar “hard science” disci- plines. Arxiv papers may represent the cutting edge of research in these fields (Eger et al., 2018). On the other hand, non-Arxiv SemanticScholar papers encompass a broad range of academic disciplines, including the humanities and social sciences. We do not automatically classify papers but resort to manual annotation, which is feasible given that there are only ∼150 papers in our dataset, see Table 6.
Annotation scheme
three dimensions:
We classify papers along
(i) their quality assessment of ChatGPT. The range is 1-5, where 1 indicates very low and 5 very high assessment, 3 is neutral. NAN indicates that the paper does not discuss the quality of ChatGPT.
(ii) their topic. After checking the papers and some discussion, we decided on six different topics. These are Ethics (which includes bi- ases, fairness, security, etc.), Education, Eval- uation (which includes reasoning, arithmetic, logic problems, etc. on which ChatGPT is evaluated), Medical, Application (which in- cludes writing assistance or using ChatGPT in downstream tasks such as argument min- ing, coding, etc.) and Rest. We note that a 
given paper could typically be classified into multiple classes, but we are interested in the dominant class.
(iii) their impact on society. We distinguish Op- portunity, Threat, Mixed (when a paper high- lights both risks and opportunities) or NAN (when the paper does not discuss this aspect).
Example annotations are shown in Table 5.

Annotation outcomes Four co-authors of this paper (three male PhD students and one male fac- ulty member) initially annotated 10 papers on all three dimensions independently without guidelines. Agreements were low across all dimensions. After a discussion of disagreements, we devised guide- lines for subsequent annotation of 10 further papers. This included (among others) to only look at pa- per abstracts for classification, as the annotation process would otherwise be too time-consuming, and which labels to prioritize in ambiguous cases. Abstracts are a good compromise because abstracts are (highly condensed) summaries of scientific pa- pers, containing their main message. This time, agreements were high: the kappa agreement is 0.63 on average across all pairs of annotators for topic, 0.70 for impact and 0.80 Spearman for quality, averaged across annotators. In total we annotated 48 papers from Arxiv and 104 additional papers from SemanticScholar.
Analysis Figure 6 shows the topic distributions for the Arxiv papers and the papers from Seman- ticScholar. The main topics we classified for the Arxiv papers are Education and the Application in various use cases. Only few papers were classified as Medical. Conversely, SemanticScholar papers are most frequently classified as Medical and Rest. This indicates that Medical is of great concern in more applied scientific fields not covered by Arxiv papers. Further, Figure 7 shows the distributions of quality labels we annotated. The labels 4 and 
5 have high numbers of occurrences, i.e., many papers report a strong performance of ChatGPT. Figures 8a and 8b show the distributions for our annotations of the social impact. If a social impact sentiment is provided, ChatGPT is most frequently described as an opportunity. For Arxiv, the number of papers which see ChatGPT as an opportunity is the same number as papers that see it as a threat.
In the second part of the analysis we consider the annotations from Arxiv and SemanticScholar together. Figure 9 displays the intersection of per- formance quality and social impact. It shows that authors who report a high performance quality for
Table 6: Number and source of scientific papers ex- amined. Here, SemanticScholar comprises only non- Arxiv papers.
ChatGPT (4/5) in most cases also believe that it will have a positive social impact. Also, there is a high number of papers which reported no per- formance quality or social impact (NAN). Papers that report a low performance quality (1/2) either state no social impact or perceive it as Mixed or a Threat, but not as Opportunity. Figure 10 shows the intersection between performance quality and topic. For every topic, the majority of papers describe a high performance quality of ChatGPT. Also, most papers that report low quality are found for Appli- cation and Education. Lastly, Figure 11 presents the intersection of topic and social impact. Here, papers in the categories Application, Medical and Rest mostly describe ChatGPT as an opportunity for society. For Education, the number of papers that see ChatGPT as a threat is almost equal to the number of those that view it as opportunity. For Evaluation, a comparably high number of abstracts articulate mixed sentiments towards the social im- pact. Finally, in the Ethics category, ChatGPT is mostly seen as a threat.
We also consider the development of each an- notated category over time, using all considered papers from Arxiv and those of SemanticScholar that have an attached publication date. Overall, the amount of papers that is published every week is increasing, highlighting the current importance of the topic. Compared to the Twitter data, the sam- ple size of papers is small, hence, other trends are difficult to reliably describe. In Figure 12, we show that the topics Evaluation and Ethics have not been considered as a main topic in most early papers of December 2022. Further, the amount of papers in Medical and Rest increases especially since the beginning of February, showing the newly gained, widespread recognition of ChatGPT in many areas outside the NLP community.
To conclude, the analysis of papers exemplifies the explosive attention ChatGPT is getting. They mostly see ChatGPT as an opportunity for society and praise its performance. Threats perceived in Education and Ethics could for example be linked 
2.3 Other sources
Up to now, we analyzed the public opin- ion of the ChatGPT model by analyzing arXiv/SemanticScholar papers and Twitter for sen- timent.
However, it is important to note that there are other resources that can provide valuable insights into the model. One such resource is GitHub repositories, which contain a wealth of informa- tion about the ChatGPT model. This includes third- party libraries that can be used to programmatically leverage or even enhance the functionality of the model,13 as well as lists of prompts that can be used to test its abilities.14
Other valuable resource are blog posts and the discussion of failure cases,15 which can help us understand the limitations of the model and how they can be addressed. These resources provide important feedback to the developers and can in- form future development efforts, ensuring that the ChatGPT model continues to evolve and improve.
We constructed a small dataset (50 entries) of such online resources and enlisted two cowork- ers to annotate their sentiment. Our analysis of these resources (see Table 8) reveals that shared prompts lists, as well as other GitHub reposito- ries exhibit overwhelmingly positive sentiment, while blog posts display a mix of positive, neu- tral, and negative sentiments in nearly equal pro- portions. We further observed that lists of failure cases showed the poorest overall sentiment, a find- ing which intuitively makes sense. Failure cases often involve math problems,16 a domain where ChatGPT frequently provides confidently incorrect answers. However, our findings were not entirely cons istent, as some positive blog posts suggest that ChatGPT performs well in symbolic execution of code,17 indicating that the issue may lie in prompt tuning rather than ChatGPT’s general capabilities, i.e., ChatpGPT can handle math problems better when they are formulated as programs, not prose. Neutral18 and negative19 blog posts tend to focus less on the quality of ChatGPT’s outputs and more on concerns related to OpenAI’s restrictions or po- tential negative social impacts.
3 Related work
The two most closely related works are Haque et al. (2022); Borji (2023). Haque et al. (2022) study twitter reception of ChatGPT after about 2 weeks, finding that the majority of tweets have been over- whelmingly positive in this early period. They have much smaller samples which they manually anno- tate and use unsupervised topic modeling to deter- mine topics. They also do not look at scientific papers, but only at social media posts. Borji (2023) presents a catalogue of failure cases of ChatGPT relating to reasoning, logic, arithmetic, factuality, bias and discrimination, etc. The failure cases are based on selected examples mostly from social me- dia. Bowman (2022); Beese et al. (2022) discuss the increase of negative papers over time using NLP tools, which is also related to our study. In contrast to their work, we only discuss very recent trends over the last months; our methodological setup is also very different.
4 Conclusion
In this paper, we conducted a comprehensive analy- sis of the perception of ChatGPT, a chatbot released by OpenAI in November 2022 that has attracted over 100 million subscribers in only two months. We analyzed over 300k tweets and more than 150 scientific papers to understand how ChatGPT is viewed from different perspectives, how its percep- tion has changed over time, and what its strengths and limitations are. We found that ChatGPT is gen- erally perceived positively, with high quality, and associated emotions of joy dominating. However, its perception has slightly decreased since its debut, and in languages other than English, it is perceived with more negative sentiment. Moreover, while ChatGPT is viewed as a great opportunity across various scientific fields, including the medical do- main, it is also seen as a threat from an ethical perspective and in the education domain. Our find- ings contribute to shaping the public debate and informing the future development of ChatGPT.
Future work should investigate developments over longer stretches of time, consider popularity of tweets and papers (via likes and citations), in- vestigate more dimensions besides sentiment and emotion and look at the expertise of social media actors and their geographic and demographic distri- bution. Finally, as language models like ChatGPT continue to evolve and gain more capabilities, fu- ture research can assess their real (rather than antic- ipated) impact on society, including their potential to exacerbate and mitigate existing inequalities and biases.
5 Limitations and Ethical Considerations
In this work, we automatically analyzed social media posts using NLP technology like senti- ment and emotion classifiers and machine trans- lation systems, which are error prone. Our se- lection of tweets was biased via the employed hashtag, i.e., #ChatGPT. Our human annotation was in some cases subjective and not without dis- agreements among annotators. Our selection of SemanticScholar papers was determined by the search results of SemanticScholar, which seem non- deterministic. Our search for papers on Arxiv was restricted to mentions in the abstracts and titles of papers and our annotations were only based on titles and abstracts. We freely used ChatGPT as an aide throughout the writing process. All errors, however, are our own.

6 Acknowledgments
Ran Zhang, Christoph Leiter, Daniil Larionov are financed by the BMBF project “Metrics4NLG”. Steffen Eger is financed by DFG Heisenberg grant EG 375/5–1. This paper was written while on a re- treat in the Austrian mountains in the small village of Hinterriß.
