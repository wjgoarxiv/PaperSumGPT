{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjgoarxiv/PaperSumGPT/blob/main/MS%EC%95%A0%EC%A0%80%ED%86%A4_API%EA%B8%B0%EB%B0%98%EC%84%9C%EB%B9%84%EC%8A%A4_%EB%85%BC%EB%AC%B8%EC%9A%94%EC%95%BD%EA%B8%B0_V1_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y86AHK4ICDG_"
      },
      "source": [
        "# **논문 요약기 V1.0.0**\n",
        "> Written by __Team 두부__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J48xwJH3T2Aa",
        "outputId": "df176c9a-71e6-4e53-ba95-d91911e8d483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: 설치가 완료되었어요!\n"
          ]
        }
      ],
      "source": [
        "#@title ## **1. 라이브러리 설치하기**\n",
        "#@markdown 왼쪽의 __\"실행\"__ 버튼을 눌러 필요한 라이브러리들을 설치해주세요. <br/> 설치에는 다소 시간이 소요될 수 있어요. <br/>\n",
        "#@markdown > **설치 라이브러리 모음**\n",
        "#@markdown > <br/> `pyfiglet`\n",
        "#@markdown > <br/> `pexpect`\n",
        "#@markdown > <br/> `openai`\n",
        "#@markdown > <br/> `tabulate`\n",
        "#@markdown > <br/> `fitz`\n",
        "#@markdown > <br/> `pdf2image`\n",
        "#@markdown > <br/> `pytesseract`\n",
        "#@markdown > <br/> `frontend`\n",
        "#@markdown > <br/> `opencv-contrib-python`\n",
        "#@markdown > <br/> `pillow`\n",
        "\n",
        "%%bash\n",
        "pip install pyfiglet pexpect openai tabulate fitz pdf2image pytesseract frontend opencv-contrib-python pillow -qq &> /dev/null\n",
        "pip install git+https://github.com/mmabrouk/chatgpt-wrapper &> /dev/null\n",
        "echo \"INFO: 설치가 완료되었어요!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mPKuCDWHEtwE"
      },
      "outputs": [],
      "source": [
        "#@title ## **2. API Key 입력하기** \n",
        "#@markdown https://platform.openai.com/account/api-keys 에 접속하여, API key 값을 복사해주세요. <br/> __\"실행\"__ 버튼을 클릭한 후, 복사한 API key 값을 입력해주세요. \n",
        "\n",
        "import os \n",
        "import openai \n",
        "\n",
        "your_api = input(\"INFO: 복사한 API key를 붙여넣어주세요: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = your_api\n",
        "os.system('cls' if os.name == 'nt' else 'clear')\n",
        "print(\"INFO: API key가 성공적으로 등록되었어요!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvgvD6eAYg0L",
        "outputId": "80190c67-5f1d-42bf-a18e-ebda6ff4ae91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (leave blank for passwordless login): \r\n",
            "\u001b[1;32mUser successfully registered.\u001b[0m\r\n",
            "\r\n",
            "\u001b[1;32mLogin successful.\u001b[0m\r\n",
            "\r\n",
            "\r\n",
            "             \u001b[1m\n",
            "INFO: ChatGPT API를 사용할 준비가 완료되었어요.\n"
          ]
        }
      ],
      "source": [
        "#@title **3. ChatGPT API 실행 준비하기** \n",
        "#@markdown __\"실행\"__ 버튼을 입력하여 ChatGPT API를 실행할 준비를 완료하세요.\n",
        "\n",
        "!apt-get install sqlite3 &> /dev/null\n",
        "\n",
        "import pexpect\n",
        "import os\n",
        "\n",
        "# Set the path to the SQLite binary\n",
        "sqlite_path = \"/lib/x86_64-linux-gnu/libsqlite3.so.0\"\n",
        "\n",
        "# Set the path to the SQLite database file\n",
        "db_path = \"////root/.local/share/chatgpt-wrapper/profiles/default/storage.db\"\n",
        "\n",
        "# Define the SQLite command to execute\n",
        "sqlite_command = \"{} {}\"\n",
        "\n",
        "# Start the SQLite process and connect to the database\n",
        "process = pexpect.spawn(\"chatgpt\", encoding=\"utf-8\")\n",
        "process.expect(\"Enter username\")\n",
        "\n",
        "# Send the username to the SQLite process and expect a prompt\n",
        "process.sendline(\"UserID1\")\n",
        "process.expect(\"Enter email\")\n",
        "\n",
        "# Send a blank password to the SQLite process and expect a prompt\n",
        "process.sendline(\"\")\n",
        "process.expect(\"Enter password\")\n",
        "\n",
        "# Send a blank email to the SQLite process and expect a prompt\n",
        "process.sendline(\"\")\n",
        "process.expect(\"Provide a prompt\")\n",
        "print(process.before)\n",
        "\n",
        "# Send a command to log in using pexpect\n",
        "process.sendline(\"/login UserID1\")\n",
        "process.expect(\"userid1@\")\n",
        "\n",
        "# Send a command to exit the SQLite process\n",
        "process.sendline(\"/exit\")\n",
        "process.wait()\n",
        "\n",
        "print(\"INFO: ChatGPT API를 사용할 준비가 완료되었어요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "uBlOYRYPmbw6",
        "cellView": "form",
        "outputId": "d08f048b-b8d2-426c-9f1f-a26c63ea02ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e4d3a28a-2bc4-443e-bb5f-6bda3d591e7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e4d3a28a-2bc4-443e-bb5f-6bda3d591e7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Microscopic study on the key process and influence of efficient synthesis of natural gas hydrate by in situ Raman analysis of water microstructure in dif- ferent systems with temperature drop_summary.md to Microscopic study on the key process and influence of efficient synthesis of natural gas hydrate by in situ Raman analysis of water microstructure in dif- ferent systems with temperature drop_summary.md\n",
            "INFO: 파일(들)이 성공적으로 업로드되었어요!\n"
          ]
        }
      ],
      "source": [
        "#@title ## **4. 인풋 파일 Colab에 업로드하기**\n",
        "#@markdown __\"실행\"__ 버튼을 눌러 논문 요약을 진행 할 파일을 업로드해주세요. <br/>\n",
        "#@markdown 인풋 파일로는 `.md`, `.txt`, 그리고 `.pdf` 세 가지 형태의 파일 타입을 지원하고 있습니다. <br/>\n",
        "#@markdown > __⚠️ NOTE__: PDF 파일을 선택하면, OCR 스캐닝을 이용해 이미지로부터 텍스트들을 불러오게 됩니다. 따라서 직접 정리하여 놓은 텍스트 파일보다 정확도가 다소 떨어질 수 있다는 점, 미리 알려드립니다.\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(\"INFO: 파일(들)이 성공적으로 업로드되었어요!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kTF0fnC4YUlI",
        "outputId": "5aafae88-fc9b-425c-c67f-d3370f582cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " ___                    ___            ___ ___ _____ \n",
            "| _ \\__ _ _ __  ___ _ _/ __|_  _ _ __ / __| _ \\_   _|\n",
            "|  _/ _` | '_ \\/ -_) '_\\__ \\ || | '  \\ (_ |  _/ | |  \n",
            "|_| \\__,_| .__/\\___|_| |___/\\_,_|_|_|_\\___|_|   |_|  \n",
            "         |_|                                         \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "------------------------------------------------\n",
            "궁금한 점이 있으시면 제 이메일로 메일을 보내주세요.\n",
            "\n",
            "에러나 업데이트가 필요한 부분이 있으면 알려주세요.\n",
            "\n",
            " 📨 woo_go@yahoo.com\n",
            "\n",
            "제 깃허브 (https://github.com/wjgoarxiv/papersumgpt)를 방문하셔서 더 많은 정보를 얻어보세요.\n",
            "------------------------------------------------\n",
            "\n",
            "\n",
            "INFO: 인풋 파일로 넣고자 하는 파일의 확장자를 번호 (1~3)로 선택해주세요.\n",
            "\n",
            "    1. Markdown (`.md`) file\n",
            "    2. Plain text (`.txt`) file\n",
            "    3. PDF (`.pdf`) file\n",
            "\n",
            "    : 1\n",
            "\n",
            "\n",
            "------------------------------------------------\n",
            "+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|   File number | File name                                                                                                                                                                                                    |\n",
            "|---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "|             1 | ./Microscopic study on the key process and influence of efficient synthesis of natural gas hydrate by in situ Raman analysis of water microstructure in dif- ferent systems with temperature drop_summary.md |\n",
            "|             2 | ./OUTPUT.md                                                                                                                                                                                                  |\n",
            "+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "------------------------------------------------\n",
            "\n",
            "INFO: 파일 번호를 선택하거나 \"0\"을 눌러 종료하세요: 1\n",
            "INFO: 사용할 파일 이름은 다음과 같습니다:  ./Microscopic study on the key process and influence of efficient synthesis of natural gas hydrate by in situ Raman analysis of water microstructure in dif- ferent systems with temperature drop_summary.md\n",
            "------------------------------------------------\n",
            "INFO: verbose mode (상세 모드)를 켜시겠어요? 상세 모드를 켜면 중간 결과를 확인해볼 수 있어요. (y/n): ㅜ\n",
            "------------------------------------------------\n",
            "INFO: 사용할 ChatGPT 모델의 번호를 입력해주세요:\n",
            "\n",
            "    1. default (Turbo version for ChatGPT Plus users and default version for free users)\n",
            "    2. gpt4 (Only available for ChatGPT Plus users; a little bit slower than the default model)\n",
            "    3. legacy (Only available for ChatGPT Plus users; an older version of the default model)\n",
            "\n",
            "    1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OpenAIAPI:Initiated non-streaming request with message count: 2\n",
            "DEBUG:OpenAIAPI:ChatCompletion.create with message count: 2, model: gpt-3.5-turbo, temperature: 0.9, top_p: 1, presence_penalty: 0.6, frequency_penalty: 0, stream: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "INFO: Tossing initial prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OpenAIAPI:Initiated non-streaming request with message count: 2\n",
            "DEBUG:OpenAIAPI:ChatCompletion.create with message count: 2, model: gpt-3.5-turbo, temperature: 0.9, top_p: 1, presence_penalty: 0.6, frequency_penalty: 0, stream: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: ChatGPT가 입력 내용의 요약을 시작했습니다...\n",
            "INFO: 진행 중... (1/1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OpenAIAPI:Initiated non-streaming request with message count: 2\n",
            "DEBUG:OpenAIAPI:ChatCompletion.create with message count: 2, model: gpt-3.5-turbo, temperature: 0.9, top_p: 1, presence_penalty: 0.6, frequency_penalty: 0, stream: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: 마지막 프롬프트를 전달합니다...\n",
            "INFO: ChatGPT의 응답: # **Effects of High-Intensity Interval Training on Cardiovascular Health and Body Composition**\n",
            "\n",
            "## **Introduction**\n",
            "High-Intensity Interval Training (HIIT) has become popular in recent years due to its potential benefits on cardiovascular health and body composition. The aim of this study is to investigate the effects of HIIT on cardiovascular health and body composition in sedentary adults.\n",
            "\n",
            "## **Methodology**\n",
            "### **Apparatus**\n",
            "- Treadmill\n",
            "- Heart rate monitor\n",
            "- Blood pressure monitor\n",
            "- Body composition analyzer\n",
            "\n",
            "### **Experimental procedure**\n",
            "- Participants were randomly assigned to either a HIIT group or a control group.\n",
            "- The HIIT group underwent 8 weeks of HIIT, consisting of 4-minute intervals of high-intensity exercise followed by 3-minute intervals of active recovery.\n",
            "- The control group maintained their usual sedentary lifestyle.\n",
            "- Cardiovascular health and body composition were measured at the beginning and end of the study.\n",
            "\n",
            "### **Data analysis**\n",
            "- Paired t-tests were used to compare pre- and post-study measurements within each group.\n",
            "- Independent t-tests were used to compare post-study measurements between the two groups.\n",
            "\n",
            "## **Results & discussion**\n",
            "- The HIIT group showed significant improvements in cardiovascular health, including decreased resting heart rate and blood pressure.\n",
            "- The HIIT group also showed significant improvements in body composition, including decreased body fat percentage and increased lean muscle mass.\n",
            "- The control group showed no significant changes in either cardiovascular health or body composition.\n",
            "- These results suggest that HIIT may be an effective intervention for improving both cardiovascular health and body composition in sedentary adults.\n",
            "\n",
            "## **Conclusions**\n",
            "- HIIT can have significant positive effects on both cardiovascular health and body composition in sedentary adults.\n",
            "- Further research is needed to investigate the long-term effects of HIIT and to determine the optimal frequency and duration of HIIT interventions.\n",
            "\n",
            "## **Significance of this study**\n",
            "- This study adds to the growing body of research on the benefits of HIIT.\n",
            "- The results suggest that HIIT may be a practical and time-efficient exercise intervention for sedentary adults looking to improve their cardiovascular health and body composition.\n",
            "\n",
            "## **Things to look out for in follow-up research**\n",
            "- Investigate the long-term effects of HIIT on cardiovascular health and body composition.\n",
            "- Determine the optimal frequency and duration of HIIT interventions for different populations.\n",
            "\n",
            "### **Useful references to consider**\n",
            "- Keating, S. E., Johnson, N. A., Mielke, G. I., Coombes, J. S., & Hermens, H. (2017). The effects of high-intensity interval training on cardiovascular disease risk factors in individuals with type 2 diabetes: A randomized controlled trial. International Journal of Cardiology, 245, 209-214.\n",
            "- Weston, M., Taylor, K. L., Batterham, A. M., & Hopkins, W. G. (2014). Effects of low-volume high-intensity interval training (HIT) on fitness in adults: A meta-analysis of controlled and non-controlled trials. Sports Medicine, 44(7), 1005-1017.\n",
            "- Gillen, J. B., Martin, B. J., MacInnis, M. J., Skelly, L. E., Tarnopolsky, M. A., & Gibala, M. J. (2016). Twelve weeks of sprint interval training improves indices of cardiometabolic health similar to traditional endurance training despite a five-fold lower exercise volume and time commitment. PloS one, 11(4), e0154075.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8a5062bf5233>\u001b[0m in \u001b[0;36m<cell line: 355>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-8a5062bf5233>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nINFO: 답변이 잘린 것 같나요? (y/n): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mcount_yes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "#@title ## **5. 논문 요약기 실행하기**\n",
        "#@markdown __\"실행\"__ 버튼을 눌러 논문 요약기를 실행해보세요.\n",
        "\n",
        "# ------------------ Import libraries ------------------ #\n",
        "import os\n",
        "import glob\n",
        "import pyfiglet\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from chatgpt_wrapper import OpenAIAPI\n",
        "from chatgpt_wrapper.core.config import Config\n",
        "from google.colab import files\n",
        "\n",
        "# Manipulating PDF\n",
        "import cv2\n",
        "import pytesseract as tess\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "\n",
        "# ------------------ Main code starts ------------------ #\n",
        "# Print the title \n",
        "os.system('cls' if os.name == 'nt' else 'clear')\n",
        "title = pyfiglet.figlet_format('PaperSumGPT', font = 'small')\n",
        "print('\\n')\n",
        "print(title+'\\n')\n",
        "print('\\n')\n",
        "print('------------------------------------------------')\n",
        "print('궁금한 점이 있으시면 제 이메일로 메일을 보내주세요.')\n",
        "print('\\n에러나 업데이트가 필요한 부분이 있으면 알려주세요.')\n",
        "print('\\n 📨 woo_go@yahoo.com')\n",
        "print('\\n제 깃허브 (https://github.com/wjgoarxiv/papersumgpt)를 방문하셔서 더 많은 정보를 얻어보세요.')\n",
        "print('------------------------------------------------')\n",
        "\n",
        "def main():\n",
        "    # Ask user if the brought input file is a markdown file or plain text file \n",
        "    print('\\n')\n",
        "    file_type = int(input(\"\"\"INFO: 인풋 파일로 넣고자 하는 파일의 확장자를 번호 (1~3)로 선택해주세요.\n",
        "\n",
        "    1. Markdown (`.md`) file\n",
        "    2. Plain text (`.txt`) file\n",
        "    3. PDF (`.pdf`) file\n",
        "\n",
        "    : \"\"\"))\n",
        "    print('\\n')\n",
        "    print('------------------------------------------------')\n",
        "\n",
        "    # Print the list of files in the current directory\n",
        "    if file_type == 1:\n",
        "        file_list = glob.glob('./*.md')\n",
        "        file_list = [file.split('\\\\')[-1] for file in file_list]\n",
        "        file_list.sort()\n",
        "\n",
        "    elif file_type == 2:\n",
        "        file_list = glob.glob('./*.txt')\n",
        "        file_list = [file.split('\\\\')[-1] for file in file_list]\n",
        "        file_list.sort()\n",
        "\n",
        "    elif file_type == 3:\n",
        "        file_list = glob.glob('./*.pdf')\n",
        "        file_list = [file.split('\\\\')[-1] for file in file_list]\n",
        "        file_list.sort()\n",
        "\n",
        "    # File not found error handling\n",
        "    try: \n",
        "        if len(file_list) == 0:\n",
        "            raise FileNotFoundError\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    # Alert the user \n",
        "    except: \n",
        "        print('ERROR: 현재 디렉터리에 파일이 없습니다. 디렉토리를 확인해보세요.')\n",
        "        print('------------------------------------------------')\n",
        "        exit()\n",
        "\n",
        "    # Print the list of files in the current directory\n",
        "    file_num = [] \n",
        "    for i in range(len(file_list)):\n",
        "        file_num.append(i+1)\n",
        "    print(tabulate({'File number': file_num, 'File name': file_list}, headers='keys', tablefmt='psql'))\n",
        "    print('------------------------------------------------')\n",
        "    user_input = int(input('\\nINFO: 파일 번호를 선택하거나 \"0\"을 눌러 종료하세요: '))\n",
        "\n",
        "    if user_input == 0:\n",
        "        print(\"INFO: 프로그램을 종료합니다.\")\n",
        "        exit()\n",
        "    else:\n",
        "        try: \n",
        "            print(\"INFO: 사용할 파일 이름은 다음과 같습니다: \", file_list[user_input-1])\n",
        "        except:\n",
        "            print(\"ERROR: 입력 번호가 범위를 벗어났습니다. 파일 번호를 확인하세요.\")\n",
        "            print(\"ERROR: 프로그램을 종료합니다.\")\n",
        "            exit()\n",
        "\n",
        "    # Ask user to turn on `verbose` mode. \n",
        "    # If the user turns on `verbose` mode, the program will print the intermediate results.\n",
        "    print('------------------------------------------------')\n",
        "    verbose = input(\"INFO: verbose mode (상세 모드)를 켜시겠어요? 상세 모드를 켜면 중간 결과를 확인해볼 수 있어요. (y/n): \")\n",
        "    if verbose == 'y' or verbose == 'Y':\n",
        "        verbose = True\n",
        "    elif verbose == 'n' or verbose == 'N':\n",
        "        verbose = False\n",
        "    print('------------------------------------------------')\n",
        "\n",
        "    # Ask user their desired ChatGPT model\n",
        "    chatgpt_model = input(\"\"\"INFO: 사용할 ChatGPT 모델의 번호를 입력해주세요:\n",
        "\n",
        "    1. default (Turbo version for ChatGPT Plus users and default version for free users)\n",
        "    2. gpt4 (Only available for ChatGPT Plus users; a little bit slower than the default model)\n",
        "    3. legacy (Only available for ChatGPT Plus users; an older version of the default model)\n",
        "\n",
        "    \"\"\")\n",
        "                        \n",
        "    if chatgpt_model == '1':\n",
        "        chatgpt_model = 'default'\n",
        "    elif chatgpt_model == '2':\n",
        "        chatgpt_model = 'gpt4'\n",
        "    elif chatgpt_model == '3':\n",
        "        chatgpt_model = 'legacy'\n",
        "    else:\n",
        "        print(\"ERROR: 입력 번호가 범위를 벗어났어요. 파일 번호를 확인해 주세요.\")\n",
        "        print(\"ERROR: 프로그램을 종료합니다. \")\n",
        "        exit()\n",
        "    print('------------------------------------------------')\n",
        "\n",
        "    # ------------------ Convert pdf to markdown ------------------ #\n",
        "    # This process requires following processes: \n",
        "    # 1. Convert pdf to images\n",
        "    # 2. Perform OCR\n",
        "    # 3. Convert the images to a markdown file \n",
        "\n",
        "    def pdf_to_images(pdf_file):\n",
        "        return convert_from_path(pdf_file, 500)\n",
        "    \n",
        "    def process_image(image):\n",
        "        # Convert PIL image to OpenCV image\n",
        "        original_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "        gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
        "        _, threshold_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        rectangular_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11, 11))\n",
        "        dilated_image = cv2.dilate(threshold_image, rectangular_kernel, iterations=1)\n",
        "\n",
        "        contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        copied_image = original_image.copy()\n",
        "\n",
        "        ocr_text = \"\"\n",
        "\n",
        "        for cnt in contours:\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            cropped = copied_image[y:y + h, x:x + w]\n",
        "            text = tess.image_to_string(cropped, config='--oem 3 --psm 1')\n",
        "            ocr_text += text\n",
        "\n",
        "        return ocr_text\n",
        "    \n",
        "    def perform_ocr(images):\n",
        "        ocr_text = \"\"\n",
        "        for i, image in enumerate(images):\n",
        "            text = process_image(image)\n",
        "            ocr_text += f\"Page {i+1}:\\n{text}\\n\\n\"\n",
        "        return ocr_text\n",
        "    \n",
        "    if file_type == 3:\n",
        "        print('INFO: PDF 파일을 마크다운 파일로 변환하는 중...')\n",
        "        pdf_text = perform_ocr(pdf_to_images(file_list[user_input-1]))\n",
        "\n",
        "        with open(file_list[user_input-1] + '_markdowned.md', 'w', encoding='utf-8') as f:\n",
        "            for line in pdf_text:\n",
        "                f.write(line)\n",
        "\n",
        "        file_list[user_input-1] = file_list[user_input-1] + '_markdowned.md'\n",
        "\n",
        "        print('INFO: PDF 파일이 마크다운 파일로 변환되었습니다.')\n",
        "        print('------------------------------------------------')\n",
        "\n",
        "    # ------------------ Function starts ------------------ #\n",
        "    # Load config settings\n",
        "    config = Config()\n",
        "    config.set('chat.model', chatgpt_model)\n",
        "\n",
        "    # Initialize ChatGPT\n",
        "    bot = OpenAIAPI(config)\n",
        "\n",
        "    # read input file\n",
        "    with open(file_list[user_input-1], 'r') as f:\n",
        "        input_text = f.read()\n",
        "\n",
        "    # Ask user maximum length of input text (if don't know, just input 3000)\n",
        "    max_length = 7000\n",
        "\n",
        "    # truncate input text into smaller parts\n",
        "    input_parts = [input_text[i:i+max_length] for i in range(0, len(input_text), max_length)]\n",
        "\n",
        "    # define initial prompt message\n",
        "    initial_prompt = \"Please, act as 'High-quality content abbreviator'. Since you have the input limits (OpenAI limited your input limit), you have to firstly take the all the inputs iteratively. To do this, I've already truncated the long inputs into each subpart. You'll now have to take the inputs iteratively. The important thing is that you should NOT answer directly or respond to the previous message. Make sure that you have to accomplish the task when all the inputs are given. I'll let you know if all the inputs are given.\"\n",
        "\n",
        "    # send initial prompt message to ChatGPT\n",
        "    print(\"INFO: Tossing initial prompt...\")\n",
        "    success, response, message = bot.ask(initial_prompt)\n",
        "    if success:\n",
        "        print(f\"INFO: ChatGPT가 입력 내용의 요약을 시작했습니다...\")\n",
        "    else:\n",
        "        raise RuntimeError(message)\n",
        "\n",
        "    # initialize response list\n",
        "    response_parts = []\n",
        "\n",
        "    # define prompt message while iterating over input parts and send them to ChatGPT\n",
        "    for i, part in enumerate(input_parts):\n",
        "        if i == len(input_parts) - 1:\n",
        "            prompt = f\"This is the {i+1}th part of the truncated input contents. And PLEASE! Do NOT answer and if you understood the input, just keep asking me to input the leftover contents.\\n\\n```\\n{part}\\n```\\nThank you for providing all the inputs.\"\n",
        "        else:\n",
        "            prompt = f\"This is the {i+1}th part of the truncated input contents. And PLEASE! Do NOT answer and if you understood the input, just keep asking me to input the leftover contents.\\n\\n```\\n{part}\\n```\"\n",
        "\n",
        "        print(f\"INFO: 진행 중... ({i+1}/{len(input_parts)})\")\n",
        "\n",
        "        # send prompt message and prompt part to ChatGPT\n",
        "        success, response, message = bot.ask(prompt)\n",
        "        if success:\n",
        "            response_parts.append(response)\n",
        "        else:\n",
        "            raise RuntimeError(message)\n",
        "\n",
        "        # Handling the `verbose` mode \n",
        "        if verbose == True:\n",
        "            print(f\"INFO: {i+1}/{len(input_parts)} 부분의 전달된 내용: {prompt}\")\n",
        "            print(f\"INFO: ChatGPT의 응답: {response}\")\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    # define final prompt message\n",
        "    final_prompt = \"\"\"Now, all the inputs are given to you. You should co   mbine and abbreviate all the inputs by fitting into the following markdown format. The markdown format is as follows:\n",
        "    \n",
        "    ------ TEMPLATE STARTS ------\n",
        "\n",
        "    # **[TITLE]**\n",
        "    (Bring the title from the foremost heading in the document. The powerful hint is that the title comes before the people who wrote the document.)\n",
        "\n",
        "    ## **Introduction**\n",
        "\n",
        "    ## **Methodology**\n",
        "    ### **Apparatus**\n",
        "    ### **Experimental procedure**\n",
        "    ### **Computational procedure (if exists)**\n",
        "    ### **Data analysis**\n",
        "\n",
        "    ## **Results & discussion**\n",
        "\n",
        "    ## **Conclusions**\n",
        "\n",
        "    ## **Significance of this study**\n",
        "\n",
        "    ## **Things to look out for in follow-up research**\n",
        "\n",
        "    ### **Useful references to consider**\n",
        "    ...\n",
        "\n",
        "    ------ TEMPLATE ENDS ------\n",
        "\n",
        "    And please, write the outputs thinking you are writing PPT slides. But NOT too simple. You have to write the outputs in a way that the readers can understand the contents easily.\n",
        "    Consecutively, if possible, please find some useful references (including title and authors) from Text or Markdown input file, and re-write them into `### Useful references to consider` subheader. \n",
        "    \"\"\"\n",
        "\n",
        "    # send final prompt message to ChatGPT\n",
        "    print(\"INFO: 마지막 프롬프트를 전달합니다...\")\n",
        "\n",
        "    # join response parts to form final response\n",
        "    # If final response doesn't exist, use the last response part\n",
        "    try: \n",
        "        final_response = response_parts[-1]\n",
        "    except:\n",
        "        print(\"ERROR: 목록 인덱스가 범위를 벗어났습니다. 종료 중...\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    success, response, message = bot.ask(final_prompt)\n",
        "    if success:\n",
        "        final_response = response  # Change this line\n",
        "        print(f\"INFO: ChatGPT의 응답: {response}\")\n",
        "    else:\n",
        "        raise RuntimeError(message)\n",
        "    \n",
        "    count_yes = 0\n",
        "    again_final_prompt_base = \"I think you are not done yet. Please input the leftover contents.\"\n",
        "\n",
        "    # Create a variable to store the concatenated responses\n",
        "    concatenated_responses = \"\"\n",
        "\n",
        "    while True: \n",
        "        user_input = input(\"\\nINFO: 답변이 잘린 것 같나요? (y/n): \")\n",
        "        if user_input.strip().lower() == \"y\":\n",
        "            count_yes += 1 \n",
        "            print(\"\\nINFO: 추가 답변을 요청합니다...\")\n",
        "            last_response_part = response.strip().split()[-1] # Get the last word\n",
        "            again_final_prompt = f\"{again_final_prompt_base}\" + \"\\n\" + \"However, keep in mind that you SHOULD NOT PRINT THE TEMPLATE that I gave you now on; JUST KEEP GENERATING from the truncated part. NEVER RESTART the conversation. Thank you.\"\n",
        "            success, response, message = bot.ask(again_final_prompt)\n",
        "            if success: \n",
        "                # Find the overlapping part between the last response and the new response\n",
        "                overlap_start = response.find(last_response_part)\n",
        "                if overlap_start != -1:\n",
        "                    response = response[overlap_start + len(last_response_part):]\n",
        "\n",
        "                concatenated_responses += response  # Append the response without the overlapping part to the concatenated_responses\n",
        "                print(f\"INFO: 이어진 ChatGPT의 응답: {concatenated_responses}\")\n",
        "            else:\n",
        "                raise RuntimeError(message)\n",
        "        elif user_input.strip().lower() == \"n\":\n",
        "            break\n",
        "        else: \n",
        "            print(\"ERROR: 잘못된 선택입니다. 다시 시도하세요.\")\n",
        "\n",
        "    # Concatenate all the response parts upto the number of times the user says yes. Direction: end to start\n",
        "    final_response = final_response + \"\\n\" + concatenated_responses\n",
        "\n",
        "    # prompt user to choose output format\n",
        "    output_format = input(\"\\nINFO 원하시는 출력 형식 (stream / txt / md)을 선택하세요: \")\n",
        "\n",
        "    # define maximum length of each response part to be printed at once\n",
        "    max_response_length = 3000\n",
        "\n",
        "    if output_format.lower() == \"stream\":\n",
        "        # print response parts until the full response is generated\n",
        "        i = 0\n",
        "        while i < len(final_response):\n",
        "            # print next response part\n",
        "            response_part = final_response[i:i+max_response_length]\n",
        "            print(response_part)\n",
        "            i += len(response_part)\n",
        "\n",
        "            # if there are more response parts, ask the user to continue\n",
        "            if i < len(final_response):\n",
        "                user_input = input(\"INFO: Enter 키를 눌러 계속 진행하거나 'quit'을 입력하여 종료합니다:\")\n",
        "                if user_input.strip().lower() == \"quit\":\n",
        "                    break\n",
        "                else: \n",
        "                    print(\"ERROR: 잘못된 선택입니다. 종료 중...\")\n",
        "\n",
        "    # Export the file name as same as the input file name (`file_list[user_input-1]`)\n",
        "    elif output_format.lower() == \"txt\":\n",
        "        # write response to a text file\n",
        "        with open(\"OUTPUT.txt\", \"w\") as f:\n",
        "            f.write(final_response)\n",
        "        print(\"INFO: OUTPUT.txt 파일이 저장되었어요.\")\n",
        "        files.download('./OUTPUT.txt')\n",
        "    elif output_format.lower() == \"md\":\n",
        "        # write response to a markdown file\n",
        "        with open(\"OUTPUT.md\", \"w\") as f:\n",
        "            f.write(f\"\\n{final_response}\\n\")\n",
        "        print(\"INFO: Output.md 파일이 저장되었어요.\")\n",
        "        files.download('./OUTPUT.md')\n",
        "    else:\n",
        "        print(\"ERROR: 잘못된 출력 형식을 선택하셨어요. 'stream', 'txt' 또는 'md'를 선택하세요.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## **⚠️ 예상치 못한 오류가 발생하였다면?**\n",
        "#@markdown __\"실행\"__ 버튼을 눌러 런타임을 초기화하세요. <br/> \n",
        "#@markdown 그 후, `1번`부터 다시 진행해보세요. \n",
        "\n",
        "print('INFO: 코랩 런타임을 종료합니다. 1번부터 다시 진행해보세요.')\n",
        "import time \n",
        "time.sleep(1)\n",
        "!kill -9 -1\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-DE5n1sxnXLp",
        "outputId": "f2d43ef2-2f49-424d-9839-bd1e94b31cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: 코랩 런타임을 종료합니다. 1번부터 다시 진행해보세요.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyYf1MgarRZxxF/3uo2sSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}